{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebf3086-c5f2-4764-ab28-5542eea64557",
   "metadata": {},
   "source": [
    "# 1、准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d678182-bb3d-4aa9-b47c-ea563fab152e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T03:41:54.726715Z",
     "iopub.status.busy": "2025-11-27T03:41:54.726502Z",
     "iopub.status.idle": "2025-11-27T03:41:55.881731Z",
     "shell.execute_reply": "2025-11-27T03:41:55.881176Z",
     "shell.execute_reply.started": "2025-11-27T03:41:54.726696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /mnt/workspace\n",
      "Model dir exists: True\n",
      "Train exists: True | Test exists: True\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 固定工作目录\n",
    "WORKDIR = Path(\"/mnt/workspace\")\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "# 路径设置\n",
    "MODEL_DIR = WORKDIR / \"model\" / \"autogluon_model\"\n",
    "TRAIN_PATH = Path(\"data/train.csv\")   # 相对 WORKDIR\n",
    "TEST_PATH  = Path(\"data/test.csv\")    # 相对 WORKDIR\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Model dir exists:\", MODEL_DIR.exists())\n",
    "print(\"Train exists:\", TRAIN_PATH.exists(), \"| Test exists:\", TEST_PATH.exists())\n",
    "\n",
    "# ===== 稳健 CSV 读取器 =====\n",
    "# 不同情况下读取CSV文件\n",
    "def robust_load_csv(path_like):\n",
    "    \"\"\"\n",
    "    稳健读取 CSV：\n",
    "    - 自动识别分隔符（逗号/分号/制表符）\n",
    "    - 尝试常见编码（utf-8/utf-8-sig/gbk）\n",
    "    - 确保读取到 >= 2 列（避免“一整列”问题）\n",
    "    \"\"\"\n",
    "    path = str(path_like)\n",
    "    last_exc = None\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"gbk\"]:\n",
    "        try:\n",
    "            df = pd.read_csv(path, engine=\"python\", sep=None, encoding=enc)\n",
    "            if df.shape[1] == 1:\n",
    "                # 可能是分号或制表符，重试常见分隔符\n",
    "                for sep in [\",\", \";\", \"\\t\", \"|\"]:\n",
    "                    df2 = pd.read_csv(path, engine=\"python\", sep=sep, encoding=enc)\n",
    "                    if df2.shape[1] > 1:\n",
    "                        print(f\"[robust_load_csv] encoding={enc}, sep={repr(sep)}, shape={df2.shape}\")\n",
    "                        return df2\n",
    "            else:\n",
    "                print(f\"[robust_load_csv] encoding={enc}, auto-sep, shape={df.shape}\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            continue\n",
    "    raise ValueError(f\"无法解析CSV: {path}。最后一次异常: {last_exc}\")\n",
    "\n",
    "# ===== 评估指标工具 =====\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, r2_score, mean_squared_error\n",
    "\n",
    "# 利用sklearn的工具反馈RMSE，用于回归任务\n",
    "def regression_report(y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"rmse\": float(rmse), \"r2\": float(r2)}\n",
    "\n",
    "# 计算ROC，用于binary任务\n",
    "def binary_clf_report(y_true, y_pred, y_proba=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1b = f1_score(y_true, y_pred, average=\"binary\")\n",
    "    auc = None\n",
    "    if y_proba is not None:\n",
    "        # y_proba: shape (n,) 或 (n,2)\n",
    "        if y_proba.ndim == 1:\n",
    "            prob1 = y_proba\n",
    "        else:\n",
    "            prob1 = y_proba[:, 1]\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, prob1)\n",
    "        except Exception:\n",
    "            auc = None\n",
    "    out = {\"accuracy\": float(acc), \"f1_binary\": float(f1b)}\n",
    "    if auc is not None:\n",
    "        out[\"auc\"] = float(auc)\n",
    "    return out\n",
    "\n",
    "# 分类任务的准确率\n",
    "def multiclass_clf_report(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return {\"accuracy\": float(acc), \"f1_macro\": float(f1m)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b9956-b9a9-434c-b995-af34de15a8c5",
   "metadata": {},
   "source": [
    "# 2、提取模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720a1697-0b46-4753-99f2-add4bded76d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:41:55.882739Z",
     "iopub.status.busy": "2025-11-27T03:41:55.882498Z",
     "iopub.status.idle": "2025-11-27T03:41:56.545635Z",
     "shell.execute_reply": "2025-11-27T03:41:56.545082Z",
     "shell.execute_reply.started": "2025-11-27T03:41:55.882721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Predictor Info ===\n",
      "path: /mnt/workspace/model/autogluon_model/\n",
      "label: Premium Amount\n",
      "problem_type: regression\n",
      "eval_metric: root_mean_squared_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/envs/autogluon-stable/lib/python3.10/site-packages/autogluon/common/utils/utils.py:74: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_15_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>38.260312</td>\n",
       "      <td>845.927748</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>11.939117</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_14_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>38.473516</td>\n",
       "      <td>836.048459</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>12.017005</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_13_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>38.770473</td>\n",
       "      <td>834.416426</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>11.914437</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_18_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>38.916586</td>\n",
       "      <td>833.058394</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>11.967577</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_17_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>39.156264</td>\n",
       "      <td>831.913210</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>12.049597</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_16_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>39.231844</td>\n",
       "      <td>839.283582</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>12.049350</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_22_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>40.606216</td>\n",
       "      <td>932.334380</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>12.152689</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_20_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>40.948920</td>\n",
       "      <td>929.138671</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>12.077396</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_24_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>41.005375</td>\n",
       "      <td>947.061845</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>12.010493</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WeightedEnsemble_21_L2</td>\n",
       "      <td>-1.044921</td>\n",
       "      <td>41.055010</td>\n",
       "      <td>925.403579</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>12.002737</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_19_L2</td>\n",
       "      <td>-1.044924</td>\n",
       "      <td>40.529149</td>\n",
       "      <td>908.589645</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>11.985158</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WeightedEnsemble_23_L2</td>\n",
       "      <td>-1.044930</td>\n",
       "      <td>38.429232</td>\n",
       "      <td>792.173707</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>16.438520</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_18_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.407975</td>\n",
       "      <td>146.330801</td>\n",
       "      <td>2.407975</td>\n",
       "      <td>146.330801</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_14_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.446107</td>\n",
       "      <td>111.720693</td>\n",
       "      <td>2.446107</td>\n",
       "      <td>111.720693</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_23_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.457750</td>\n",
       "      <td>148.426396</td>\n",
       "      <td>2.457750</td>\n",
       "      <td>148.426396</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_19_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.467980</td>\n",
       "      <td>145.715772</td>\n",
       "      <td>2.467980</td>\n",
       "      <td>145.715772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_22_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.477875</td>\n",
       "      <td>150.029846</td>\n",
       "      <td>2.477875</td>\n",
       "      <td>150.029846</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_16_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.478977</td>\n",
       "      <td>99.181004</td>\n",
       "      <td>2.478977</td>\n",
       "      <td>99.181004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_21_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.485026</td>\n",
       "      <td>145.864710</td>\n",
       "      <td>2.485026</td>\n",
       "      <td>145.864710</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBM_13_BAG_L1</td>\n",
       "      <td>-1.045595</td>\n",
       "      <td>2.499737</td>\n",
       "      <td>100.412827</td>\n",
       "      <td>2.499737</td>\n",
       "      <td>100.412827</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val    fit_time  \\\n",
       "0   WeightedEnsemble_15_L2  -1.044921      38.260312  845.927748   \n",
       "1   WeightedEnsemble_14_L2  -1.044921      38.473516  836.048459   \n",
       "2   WeightedEnsemble_13_L2  -1.044921      38.770473  834.416426   \n",
       "3   WeightedEnsemble_18_L2  -1.044921      38.916586  833.058394   \n",
       "4   WeightedEnsemble_17_L2  -1.044921      39.156264  831.913210   \n",
       "5   WeightedEnsemble_16_L2  -1.044921      39.231844  839.283582   \n",
       "6   WeightedEnsemble_22_L2  -1.044921      40.606216  932.334380   \n",
       "7   WeightedEnsemble_20_L2  -1.044921      40.948920  929.138671   \n",
       "8   WeightedEnsemble_24_L2  -1.044921      41.005375  947.061845   \n",
       "9   WeightedEnsemble_21_L2  -1.044921      41.055010  925.403579   \n",
       "10  WeightedEnsemble_19_L2  -1.044924      40.529149  908.589645   \n",
       "11  WeightedEnsemble_23_L2  -1.044930      38.429232  792.173707   \n",
       "12      LightGBM_18_BAG_L1  -1.045595       2.407975  146.330801   \n",
       "13      LightGBM_14_BAG_L1  -1.045595       2.446107  111.720693   \n",
       "14      LightGBM_23_BAG_L1  -1.045595       2.457750  148.426396   \n",
       "15      LightGBM_19_BAG_L1  -1.045595       2.467980  145.715772   \n",
       "16      LightGBM_22_BAG_L1  -1.045595       2.477875  150.029846   \n",
       "17      LightGBM_16_BAG_L1  -1.045595       2.478977   99.181004   \n",
       "18      LightGBM_21_BAG_L1  -1.045595       2.485026  145.864710   \n",
       "19      LightGBM_13_BAG_L1  -1.045595       2.499737  100.412827   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.013803          11.939117            2       True   \n",
       "1                 0.013598          12.017005            2       True   \n",
       "2                 0.013576          11.914437            2       True   \n",
       "3                 0.013499          11.967577            2       True   \n",
       "4                 0.013863          12.049597            2       True   \n",
       "5                 0.019447          12.049350            2       True   \n",
       "6                 0.013808          12.152689            2       True   \n",
       "7                 0.013818          12.077396            2       True   \n",
       "8                 0.014307          12.010493            2       True   \n",
       "9                 0.013661          12.002737            2       True   \n",
       "10                0.013533          11.985158            2       True   \n",
       "11                0.015973          16.438520            2       True   \n",
       "12                2.407975         146.330801            1       True   \n",
       "13                2.446107         111.720693            1       True   \n",
       "14                2.457750         148.426396            1       True   \n",
       "15                2.467980         145.715772            1       True   \n",
       "16                2.477875         150.029846            1       True   \n",
       "17                2.478977          99.181004            1       True   \n",
       "18                2.485026         145.864710            1       True   \n",
       "19                2.499737         100.412827            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          64  \n",
       "1          55  \n",
       "2          46  \n",
       "3          91  \n",
       "4          82  \n",
       "5          73  \n",
       "6         127  \n",
       "7         109  \n",
       "8         145  \n",
       "9         118  \n",
       "10        100  \n",
       "11        136  \n",
       "12         93  \n",
       "13         57  \n",
       "14        138  \n",
       "15        102  \n",
       "16        129  \n",
       "17         75  \n",
       "18        120  \n",
       "19         48  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has L2 ensemble? True\n",
      "Has L3 ensemble? True\n",
      "Best model: WeightedEnsemble_15_L2, score_val: -1.0449213176465442\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "assert MODEL_DIR.exists(), f\"主模型目录不存在: {MODEL_DIR}\"\n",
    "predictor = TabularPredictor.load(str(MODEL_DIR))\n",
    "\n",
    "print(\"=== Predictor Info ===\")\n",
    "print(\"path:\", predictor.path)\n",
    "print(\"label:\", predictor.label)\n",
    "print(\"problem_type:\", predictor.problem_type)\n",
    "print(\"eval_metric:\", predictor.eval_metric)\n",
    "\n",
    "# Leaderboard：查看模型层级/得分\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "display(lb.head(20))\n",
    "\n",
    "# 判断是否存在 L2/L3 融合\n",
    "model_names = lb[\"model\"].astype(str).tolist()\n",
    "has_L2 = any(m.startswith(\"WeightedEnsemble_L2\") for m in model_names)\n",
    "has_L3 = any(m.startswith(\"WeightedEnsemble_L3\") for m in model_names)\n",
    "print(f\"Has L2 ensemble? {has_L2}\")\n",
    "print(f\"Has L3 ensemble? {has_L3}\")\n",
    "\n",
    "# 记录最优模型\n",
    "best_row = lb.iloc[0]\n",
    "best_model_name = str(best_row[\"model\"])\n",
    "best_val_score = float(best_row[\"score_val\"]) if pd.notna(best_row.get(\"score_val\", np.nan)) else None\n",
    "print(f\"Best model: {best_model_name}, score_val: {best_val_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0c352-a29a-45ed-b659-5536a3e1ca61",
   "metadata": {},
   "source": [
    "# 3、读取测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c748b64-a7bb-4e47-a291-dff1ae1731b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:41:56.546362Z",
     "iopub.status.busy": "2025-11-27T03:41:56.546107Z",
     "iopub.status.idle": "2025-11-27T03:42:17.104070Z",
     "shell.execute_reply": "2025-11-27T03:42:17.103376Z",
     "shell.execute_reply.started": "2025-11-27T03:41:56.546346Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[robust_load_csv] encoding=utf-8, auto-sep, shape=(800000, 20)\n",
      "Test shape: (800000, 20) | has_label: False\n",
      "[robust_load_csv] encoding=utf-8, auto-sep, shape=(1200000, 21)\n",
      "Train shape: (1200000, 21)\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "assert TEST_PATH.exists(), f\"找不到测试集: {TEST_PATH}\"\n",
    "test_df = robust_load_csv(TEST_PATH)\n",
    "label = predictor.label\n",
    "\n",
    "has_test_label = (label in test_df.columns)\n",
    "X_test = test_df.drop(columns=[label]) if has_test_label else test_df.copy()\n",
    "y_test = test_df[label] if has_test_label else None\n",
    "\n",
    "print(\"Test shape:\", test_df.shape, \"| has_label:\", has_test_label)\n",
    "\n",
    "# 可选：训练集（仅用于基线训练）\n",
    "train_df = None\n",
    "if TRAIN_PATH.exists():\n",
    "    train_df = robust_load_csv(TRAIN_PATH)\n",
    "    assert label in train_df.columns, f\"训练集缺少标签列 `{label}`\"\n",
    "    print(\"Train shape:\", train_df.shape)\n",
    "else:\n",
    "    print(\"[Info] 未找到 data/train.csv，将跳过基线模型的训练。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6e7f4-a17c-4b2d-886c-15cd4c004da8",
   "metadata": {},
   "source": [
    "# 4、主模型预测，并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ac3c59-563f-458f-80d5-e19ab8b2afe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:42:17.104784Z",
     "iopub.status.busy": "2025-11-27T03:42:17.104614Z",
     "iopub.status.idle": "2025-11-27T03:43:30.731773Z",
     "shell.execute_reply": "2025-11-27T03:43:30.731168Z",
     "shell.execute_reply.started": "2025-11-27T03:42:17.104767Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/workspace/predictions_main.csv\n",
      "main_model: {'test_metrics': None, 'predictions_csv': '/mnt/workspace/predictions_main.csv'}\n"
     ]
    }
   ],
   "source": [
    "# 主模型预测\n",
    "main_preds = predictor.predict(X_test)\n",
    "\n",
    "# 导出：保留原测试表的列 + 主模型预测\n",
    "main_out = test_df.copy()\n",
    "main_out[\"main_pred\"] = main_preds\n",
    "\n",
    "pred_main_path = WORKDIR / \"predictions_main.csv\"\n",
    "main_out.to_csv(pred_main_path, index=False)\n",
    "print(\"Saved:\", pred_main_path)\n",
    "\n",
    "# 计算主模型测试指标（若测试集带标签）\n",
    "main_metrics = None\n",
    "if y_test is not None:\n",
    "    if predictor.problem_type == \"regression\":\n",
    "        main_metrics = regression_report(y_test, main_preds)\n",
    "    elif predictor.problem_type == \"binary\":\n",
    "        try:\n",
    "            proba = predictor.predict_proba(X_test)\n",
    "        except Exception:\n",
    "            proba = None\n",
    "        main_metrics = binary_clf_report(y_test, main_preds, proba)\n",
    "    else:\n",
    "        main_metrics = multiclass_clf_report(y_test, main_preds)\n",
    "\n",
    "# 结果块：main_model（只放结果，不放模型对象）\n",
    "main_model = {\n",
    "    \"test_metrics\": main_metrics,   # None 表示测试集无标签，无法评估\n",
    "    \"predictions_csv\": str(pred_main_path)\n",
    "}\n",
    "print(\"main_model:\", main_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108a901-3058-4de8-b7ee-b102a4afe467",
   "metadata": {},
   "source": [
    "# 5、在主模型基础上生成基线模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9093c9-8a40-4a88-b914-d4bd108259e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:43:30.732476Z",
     "iopub.status.busy": "2025-11-27T03:43:30.732302Z",
     "iopub.status.idle": "2025-11-27T03:44:36.314032Z",
     "shell.execute_reply": "2025-11-27T03:44:36.313371Z",
     "shell.execute_reply.started": "2025-11-27T03:43:30.732461Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/mnt/workspace/model/baseline_autogluon\"\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/mnt/workspace/model/baseline_autogluon/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jul 17 11:00:10 CST 2025\n",
      "Disk Space Avail:   53.07 GB / 105.09 GB (50.5%)\n",
      "Train Data Rows:    1200000\n",
      "Train Data Columns: 20\n",
      "Label Column: Premium Amount\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27110.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 931.82 MB (3.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\t\t('int', [])                        :  1 | ['id']\n",
      "\t\t('object', [])                     : 10 | ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['Policy Start Date']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 8 | ['Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', ...]\n",
      "\t\t('float', [])                : 8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\t\t('int', [])                  : 1 | ['id']\n",
      "\t\t('int', ['bool'])            : 2 | ['Gender', 'Smoking Status']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['Policy Start Date', 'Policy Start Date.year', 'Policy Start Date.month', 'Policy Start Date.day', 'Policy Start Date.dayofweek']\n",
      "\t6.0s = Fit runtime\n",
      "\t20 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 146.4 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.47s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 1188000, Val Rows: 12000\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': {},\n",
      "\t'XT': {},\n",
      "\t'LR': {},\n",
      "}\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: RandomForest ... Training model for up to 53.53s of the 53.52s of remaining time.\n",
      "\tWarning: Model is expected to require 855.1s to train, which exceeds the maximum time limit of 53.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForest.\n",
      "Fitting model: ExtraTrees ... Training model for up to 41.76s of the 41.76s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 46 due to low time. Expected time usage reduced from 270.8s -> 41.8s...\n",
      "\t-833.2255\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LinearModel ... Training model for up to 7.22s of the 7.22s of remaining time.\n",
      "\t-854.0747\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 53.53s of the 2.93s of remaining time.\n",
      "\t-833.1176\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 57.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/mnt/workspace/model/baseline_autogluon/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-833.117603</td>\n",
       "      <td>0.052069</td>\n",
       "      <td>38.688019</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.119101</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>-833.225455</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>34.300343</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>34.300343</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearModel</td>\n",
       "      <td>-854.074712</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>4.268575</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>4.268575</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   score_val  pred_time_val   fit_time  \\\n",
       "0  WeightedEnsemble_L2 -833.117603       0.052069  38.688019   \n",
       "1           ExtraTrees -833.225455       0.029383  34.300343   \n",
       "2          LinearModel -854.074712       0.022253   4.268575   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000434           0.119101            2       True   \n",
       "1                0.029383          34.300343            1       True   \n",
       "2                0.022253           4.268575            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          3  \n",
       "1          1  \n",
       "2          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /mnt/workspace/predictions_baseline.csv\n",
      "baseline_model: {'trained': True, 'leaderboard_top': {'model': ['WeightedEnsemble_L2', 'ExtraTrees', 'LinearModel'], 'score_val': [-833.1176032828895, -833.2254546001295, -854.0747116246549], 'pred_time_val': [0.05206942558288574, 0.029382944107055664, 0.022252798080444336], 'fit_time': [38.688018560409546, 34.30034279823303, 4.268575191497803], 'pred_time_val_marginal': [0.0004336833953857422, 0.029382944107055664, 0.022252798080444336], 'fit_time_marginal': [0.11910057067871094, 34.30034279823303, 4.268575191497803], 'stack_level': [2, 1, 1], 'can_infer': [True, True, True], 'fit_order': [3, 1, 2]}, 'test_metrics': None, 'predictions_csv': '/mnt/workspace/predictions_baseline.csv'}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "baseline_predictor = None\n",
    "baseline_model = {\n",
    "    \"trained\": False,\n",
    "    \"leaderboard_top\": None,\n",
    "    \"test_metrics\": None,\n",
    "    \"predictions_csv\": None,\n",
    "}\n",
    "\n",
    "if train_df is not None:\n",
    "    # 转为 AutoGluon 数据集（可直接用 pandas 也行，这里保持一致）\n",
    "    ag_train = TabularDataset(train_df)\n",
    "\n",
    "    # 轻量基线：快速可比\n",
    "    baseline_hparams = {\n",
    "        \"RF\": {},\n",
    "        \"XT\": {},\n",
    "        \"LR\": {},\n",
    "    }\n",
    "\n",
    "    BASELINE_DIR = WORKDIR / \"model\" / \"baseline_autogluon\"\n",
    "    BASELINE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    baseline_predictor = TabularPredictor(\n",
    "        label=label,\n",
    "        path=str(BASELINE_DIR),\n",
    "        problem_type=predictor.problem_type,\n",
    "        eval_metric=predictor.eval_metric,\n",
    "        verbosity=2,\n",
    "    ).fit(\n",
    "        train_data=ag_train,\n",
    "        time_limit=60,                 # 轻量快速\n",
    "        hyperparameters=baseline_hparams\n",
    "    )\n",
    "\n",
    "    # 基线模型排行榜\n",
    "    b_lb = baseline_predictor.leaderboard(silent=True)\n",
    "    display(b_lb)\n",
    "\n",
    "    # 基线预测与导出\n",
    "    baseline_preds = baseline_predictor.predict(X_test)\n",
    "    baseline_out = test_df.copy()\n",
    "    baseline_out[\"baseline_pred\"] = baseline_preds\n",
    "    pred_baseline_path = WORKDIR / \"predictions_baseline.csv\"\n",
    "    baseline_out.to_csv(pred_baseline_path, index=False)\n",
    "    print(\"Saved:\", pred_baseline_path)\n",
    "\n",
    "    # 基线指标（若测试集带标签）\n",
    "    bm = None\n",
    "    if y_test is not None:\n",
    "        if predictor.problem_type == \"regression\":\n",
    "            bm = regression_report(y_test, baseline_preds)\n",
    "        elif predictor.problem_type == \"binary\":\n",
    "            try:\n",
    "                b_proba = baseline_predictor.predict_proba(X_test)\n",
    "            except Exception:\n",
    "                b_proba = None\n",
    "            bm = binary_clf_report(y_test, baseline_preds, b_proba)\n",
    "        else:\n",
    "            bm = multiclass_clf_report(y_test, baseline_preds)\n",
    "\n",
    "    baseline_model = {\n",
    "        \"trained\": True,\n",
    "        \"leaderboard_top\": b_lb.head(3).to_dict(orient=\"list\"),\n",
    "        \"test_metrics\": bm,\n",
    "        \"predictions_csv\": str(pred_baseline_path),\n",
    "    }\n",
    "    print(\"baseline_model:\", baseline_model)\n",
    "else:\n",
    "    print(\"未训练基线模型（缺少 data/train.csv）。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea703ffc-afd9-41d6-8ef5-37c8a5008d6e",
   "metadata": {},
   "source": [
    "# 6、汇总主模型与基线模型的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd004e8-1a24-4834-99dd-3c94e9cc1e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:44:36.314725Z",
     "iopub.status.busy": "2025-11-27T03:44:36.314561Z",
     "iopub.status.idle": "2025-11-27T03:44:36.320569Z",
     "shell.execute_reply": "2025-11-27T03:44:36.320108Z",
     "shell.execute_reply.started": "2025-11-27T03:44:36.314709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary JSON saved ===\n",
      "/mnt/workspace/model_analysis_summary.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictor': {'path': '/mnt/workspace/model/autogluon_model/',\n",
       "  'label': 'Premium Amount',\n",
       "  'problem_type': 'regression',\n",
       "  'eval_metric': 'root_mean_squared_error',\n",
       "  'has_L2': True,\n",
       "  'has_L3': True,\n",
       "  'best_model': 'WeightedEnsemble_15_L2',\n",
       "  'best_score_val': -1.0449213176465442},\n",
       " 'main_model': {'test_metrics': None,\n",
       "  'predictions_csv': '/mnt/workspace/predictions_main.csv'},\n",
       " 'baseline_model': {'trained': True,\n",
       "  'leaderboard_top': {'model': ['WeightedEnsemble_L2',\n",
       "    'ExtraTrees',\n",
       "    'LinearModel'],\n",
       "   'score_val': [-833.1176032828895, -833.2254546001295, -854.0747116246549],\n",
       "   'pred_time_val': [0.05206942558288574,\n",
       "    0.029382944107055664,\n",
       "    0.022252798080444336],\n",
       "   'fit_time': [38.688018560409546, 34.30034279823303, 4.268575191497803],\n",
       "   'pred_time_val_marginal': [0.0004336833953857422,\n",
       "    0.029382944107055664,\n",
       "    0.022252798080444336],\n",
       "   'fit_time_marginal': [0.11910057067871094,\n",
       "    34.30034279823303,\n",
       "    4.268575191497803],\n",
       "   'stack_level': [2, 1, 1],\n",
       "   'can_infer': [True, True, True],\n",
       "   'fit_order': [3, 1, 2]},\n",
       "  'test_metrics': None,\n",
       "  'predictions_csv': '/mnt/workspace/predictions_baseline.csv'},\n",
       " 'has_baseline_predictor': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"predictor\": {\n",
    "        \"path\": predictor.path,\n",
    "        \"label\": predictor.label,\n",
    "        \"problem_type\": predictor.problem_type,\n",
    "        \"eval_metric\": str(predictor.eval_metric),\n",
    "        \"has_L2\": bool(has_L2),\n",
    "        \"has_L3\": bool(has_L3),\n",
    "        \"best_model\": str(best_model_name),\n",
    "        \"best_score_val\": None if best_val_score is None else float(best_val_score),\n",
    "    },\n",
    "    \"main_model\": main_model,                     # 主模型的结果块\n",
    "    \"baseline_model\": baseline_model,             # 基线模型的结果块\n",
    "    \"has_baseline_predictor\": baseline_predictor is not None,\n",
    "}\n",
    "\n",
    "out_path = WORKDIR / \"model_analysis_summary.json\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"=== Summary JSON saved ===\")\n",
    "print(out_path)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75b7674-44cf-494f-ad3b-03ac297eaed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:44:36.321339Z",
     "iopub.status.busy": "2025-11-27T03:44:36.321059Z",
     "iopub.status.idle": "2025-11-27T03:44:36.538331Z",
     "shell.execute_reply": "2025-11-27T03:44:36.537647Z",
     "shell.execute_reply.started": "2025-11-27T03:44:36.321322Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pred_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoGluon Main</td>\n",
       "      <td>/mnt/workspace/predictions_main.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline (Light)</td>\n",
       "      <td>/mnt/workspace/predictions_baseline.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model                                 pred_csv\n",
       "0    AutoGluon Main      /mnt/workspace/predictions_main.csv\n",
       "1  Baseline (Light)  /mnt/workspace/predictions_baseline.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# 主模型\n",
    "mm = main_model.get(\"test_metrics\")\n",
    "rows.append({\n",
    "    \"model\": \"AutoGluon Main\",\n",
    "    **({} if mm is None else mm),\n",
    "    \"pred_csv\": main_model.get(\"predictions_csv\")\n",
    "})\n",
    "\n",
    "# 基线\n",
    "bm = baseline_model.get(\"test_metrics\")\n",
    "rows.append({\n",
    "    \"model\": \"Baseline (Light)\",\n",
    "    **({} if bm is None else bm),\n",
    "    \"pred_csv\": baseline_model.get(\"predictions_csv\")\n",
    "})\n",
    "\n",
    "df_compare = pd.DataFrame(rows)\n",
    "display(df_compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe21743-230c-4b3d-9833-a6ad80bad81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T06:21:59.837577Z",
     "iopub.status.busy": "2025-11-28T06:21:59.837266Z",
     "iopub.status.idle": "2025-11-28T06:21:59.840027Z",
     "shell.execute_reply": "2025-11-28T06:21:59.839370Z",
     "shell.execute_reply.started": "2025-11-28T06:21:59.837558Z"
    },
    "tags": []
   },
   "source": [
    "# 7、提交kaggle数据集，提交前进行EXP处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410cfb08-c973-44e5-b6c2-e978903e803a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T03:44:36.538900Z",
     "iopub.status.busy": "2025-11-27T03:44:36.538745Z",
     "iopub.status.idle": "2025-11-27T03:44:39.083021Z",
     "shell.execute_reply": "2025-11-27T03:44:39.082445Z",
     "shell.execute_reply.started": "2025-11-27T03:44:36.538885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已生成 Kaggle 提交文件: /mnt/workspace/data/submission.csv\n",
      "列示例：\n",
      "        id  Premium Amount\n",
      "0  1200000      759.853934\n",
      "1  1200001      801.764744\n",
      "2  1200002      794.337299\n",
      "\n",
      "[Preview] 提交目标列统计：\n",
      "count    800000.000000\n",
      "mean        757.499200\n",
      "std         153.447147\n",
      "min         142.516872\n",
      "1%          184.764305\n",
      "50%         793.769949\n",
      "99%         979.566096\n",
      "max        1252.986556\n",
      "Name: Premium Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Kaggle 提交文件生成器（支持从对数空间还原） ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# === 配置：根据你的训练目标变换选择 ===\n",
    "#   - \"log1p\" : 训练用了 log1p(y)  →  预测需 expm1 还原\n",
    "#   - \"log\"   : 训练用了 log(y)    →  预测需 exp 还原\n",
    "#   - None    : 没有对数变换       →  不做还原\n",
    "TRANSFORM = \"log1p\"     # ← 按需改为 \"log\" 或 None\n",
    "CLIP_MIN_ZERO = True    # RMSLE 要求非负，必要时把负值裁为 0\n",
    "\n",
    "WORKDIR = Path(\"/mnt/workspace\")\n",
    "SAMPLE_PATH = WORKDIR / \"data\" / \"sample_submission.csv\"\n",
    "PRED_PATH   = WORKDIR / \"predictions_main.csv\"     # 如需基线提交，可改为 \"predictions_baseline.csv\"\n",
    "OUT_PATH    = WORKDIR / \"data\" / \"submission.csv\"\n",
    "\n",
    "assert SAMPLE_PATH.exists(), f\"找不到 sample_submission: {SAMPLE_PATH}\"\n",
    "assert PRED_PATH.exists(),   f\"找不到预测文件: {PRED_PATH}\"\n",
    "\n",
    "sample = pd.read_csv(SAMPLE_PATH)\n",
    "preds  = pd.read_csv(PRED_PATH)\n",
    "\n",
    "# 1) 识别 sample 中的 id 列与目标列（通常 1 个目标列）\n",
    "sample_cols = sample.columns.tolist()\n",
    "if \"id\" in sample_cols:\n",
    "    id_col = \"id\"\n",
    "elif \"ID\" in sample_cols:\n",
    "    id_col = \"ID\"\n",
    "else:\n",
    "    id_col = sample_cols[0]\n",
    "\n",
    "target_cols = [c for c in sample_cols if c != id_col]\n",
    "assert len(target_cols) >= 1, \"sample_submission 里没找到目标列\"\n",
    "if len(target_cols) > 1:\n",
    "    print(\"[Warn] sample_submission 中目标列>1，将全部保留。\")\n",
    "\n",
    "# 2) 识别预测列：优先 main_pred，其次 prediction；否则尝试最后一列\n",
    "candidate_pred_cols = [c for c in [\"main_pred\", \"prediction\"] if c in preds.columns]\n",
    "if candidate_pred_cols:\n",
    "    pred_col = candidate_pred_cols[0]\n",
    "else:\n",
    "    common_meta = {id_col, \"id\", \"ID\"}\n",
    "    remaining = [c for c in preds.columns if c not in common_meta]\n",
    "    pred_col = remaining[-1] if remaining else preds.columns[-1]\n",
    "    print(f\"[Info] 未找到 main_pred/prediction，改用列: {pred_col}\")\n",
    "\n",
    "# 2.5) 进行“从对数空间还原” + 合规性处理（RMSLE 需要非负）\n",
    "def inverse_transform(x: pd.Series, mode: str | None):\n",
    "    x = x.astype(float)\n",
    "    if mode == \"log1p\":\n",
    "        x = np.expm1(x)     # y = exp(pred_log1p) - 1\n",
    "    elif mode == \"log\":\n",
    "        x = np.exp(x)       # y = exp(pred_log)\n",
    "    # 裁负（RMSLE 要求预测非负；多数比赛 target 也非负）\n",
    "    if CLIP_MIN_ZERO:\n",
    "        x = np.clip(x, 0, None)\n",
    "    return x\n",
    "\n",
    "# 3) 优先按 id 合并；若预测里没有 id 列，则按行顺序对齐\n",
    "if id_col in preds.columns:\n",
    "    preds_narrow = preds[[id_col, pred_col]].copy()\n",
    "    preds_narrow[pred_col] = inverse_transform(preds_narrow[pred_col], TRANSFORM)\n",
    "\n",
    "    sub = sample[[id_col] + target_cols].copy()\n",
    "    for tcol in target_cols:\n",
    "        sub[tcol] = None\n",
    "    sub = sub.merge(preds_narrow, on=id_col, how=\"left\")\n",
    "    sub[target_cols[0]] = sub[pred_col]\n",
    "    sub = sub[[id_col] + target_cols]\n",
    "else:\n",
    "    print(f\"[Warn] 预测文件中缺少 {id_col}，按行序对齐（务必确保与 sample 同顺序）\")\n",
    "    assert len(preds) == len(sample), \"无法按行对齐：行数不一致\"\n",
    "    restored = inverse_transform(preds[pred_col], TRANSFORM)\n",
    "    sub = sample.copy()\n",
    "    sub[target_cols[0]] = restored.values\n",
    "\n",
    "# 4) 保存\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "sub.to_csv(OUT_PATH, index=False)\n",
    "print(f\"✅ 已生成 Kaggle 提交文件: {OUT_PATH}\")\n",
    "print(\"列示例：\")\n",
    "print(sub.head(3))\n",
    "\n",
    "# 5) 可选：简单统计，确认数值合理性\n",
    "col_preview = target_cols[0]\n",
    "print(\"\\n[Preview] 提交目标列统计：\")\n",
    "print(sub[col_preview].describe(percentiles=[0.01, 0.5, 0.99]))\n",
    "num_neg = (sub[col_preview] < 0).sum()\n",
    "if num_neg > 0:\n",
    "    print(f\"[Warn] 仍有 {num_neg} 个负值（RMSLE 不允许），请检查变换与裁剪逻辑。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b52d8d-7ccf-4320-a20f-0470744f3896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoGluon Stable",
   "language": "python",
   "name": "autogluon-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
